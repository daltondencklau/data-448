{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31acfe01-3601-4e53-a99d-f51579b052dd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting pandas-profiling\n",
      "  Downloading pandas_profiling-3.6.3-py2.py3-none-any.whl (328 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.8/328.8 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib<3.7,>=3.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas-profiling) (3.6.1)\n",
      "Collecting visions[type_image_path]==0.7.5\n",
      "  Downloading visions-0.7.5-py3-none-any.whl (102 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.7/102.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typeguard<2.14,>=2.13.2\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: jinja2<3.2,>=2.11.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas-profiling) (3.1.2)\n",
      "Collecting htmlmin==0.1.12\n",
      "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas!=1.4.0,<1.6,>1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas-profiling) (1.5.1)\n",
      "Collecting pydantic<1.11,>=1.8.1\n",
      "  Downloading pydantic-1.10.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<1.24,>=1.16.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas-profiling) (1.22.4)\n",
      "Requirement already satisfied: statsmodels<0.14,>=0.13.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas-profiling) (0.13.2)\n",
      "Collecting phik<0.13,>=0.11.1\n",
      "  Downloading phik-0.12.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (679 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m679.5/679.5 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: seaborn<0.13,>=0.10.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas-profiling) (0.12.0)\n",
      "Requirement already satisfied: requests<2.29,>=2.24.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas-profiling) (2.28.1)\n",
      "Requirement already satisfied: scipy<1.10,>=1.4.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas-profiling) (1.9.3)\n",
      "Requirement already satisfied: tqdm<4.65,>=4.48.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas-profiling) (4.64.1)\n",
      "Collecting multimethod<1.10,>=1.4\n",
      "  Downloading multimethod-1.9.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas-profiling) (5.4.1)\n",
      "Requirement already satisfied: attrs>=19.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from visions[type_image_path]==0.7.5->pandas-profiling) (22.1.0)\n",
      "Collecting tangled-up-in-unicode>=0.0.4\n",
      "  Downloading tangled_up_in_unicode-0.2.0-py3-none-any.whl (4.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: networkx>=2.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from visions[type_image_path]==0.7.5->pandas-profiling) (2.8.7)\n",
      "Requirement already satisfied: Pillow in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from visions[type_image_path]==0.7.5->pandas-profiling) (9.2.0)\n",
      "Collecting imagehash\n",
      "  Downloading ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.5/296.5 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinja2<3.2,>=2.11.1->pandas-profiling) (2.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib<3.7,>=3.2->pandas-profiling) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib<3.7,>=3.2->pandas-profiling) (4.38.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib<3.7,>=3.2->pandas-profiling) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib<3.7,>=3.2->pandas-profiling) (1.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib<3.7,>=3.2->pandas-profiling) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib<3.7,>=3.2->pandas-profiling) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib<3.7,>=3.2->pandas-profiling) (1.4.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas!=1.4.0,<1.6,>1.1->pandas-profiling) (2022.5)\n",
      "Requirement already satisfied: joblib>=0.14.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from phik<0.13,>=0.11.1->pandas-profiling) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<1.11,>=1.8.1->pandas-profiling) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<2.29,>=2.24.0->pandas-profiling) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<2.29,>=2.24.0->pandas-profiling) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<2.29,>=2.24.0->pandas-profiling) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<2.29,>=2.24.0->pandas-profiling) (2022.9.24)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from statsmodels<0.14,>=0.13.2->pandas-profiling) (0.5.3)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from patsy>=0.5.2->statsmodels<0.14,>=0.13.2->pandas-profiling) (1.16.0)\n",
      "Requirement already satisfied: PyWavelets in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from imagehash->visions[type_image_path]==0.7.5->pandas-profiling) (1.3.0)\n",
      "Building wheels for collected packages: htmlmin\n",
      "  Building wheel for htmlmin (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27082 sha256=133d96c0b20755b72c089ef3e8c6a3c3aa1c6b21d02c542d9b821ddf34116dd2\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/ea/1c/a8/5cec3479cd45136a7111e2d96aac299b219b199c411665250b\n",
      "Successfully built htmlmin\n",
      "Installing collected packages: htmlmin, typeguard, tangled-up-in-unicode, pydantic, multimethod, imagehash, visions, phik, pandas-profiling\n",
      "Successfully installed htmlmin-0.1.12 imagehash-4.3.1 multimethod-1.9.1 pandas-profiling-3.6.3 phik-0.12.3 pydantic-1.10.4 tangled-up-in-unicode-0.2.0 typeguard-2.13.3 visions-0.7.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f388ffd-ae01-43dd-8c7d-b4cb8c700a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fresh</th>\n",
       "      <th>Milk</th>\n",
       "      <th>Grocery</th>\n",
       "      <th>Frozen</th>\n",
       "      <th>Detergents_Paper</th>\n",
       "      <th>Delicassen</th>\n",
       "      <th>Channel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6623.613537</td>\n",
       "      <td>5513.093240</td>\n",
       "      <td>6019.057354</td>\n",
       "      <td>5669.568008</td>\n",
       "      <td>5898.660607</td>\n",
       "      <td>5179.234947</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5642.542497</td>\n",
       "      <td>5829.866565</td>\n",
       "      <td>3960.339943</td>\n",
       "      <td>4270.020548</td>\n",
       "      <td>3498.818262</td>\n",
       "      <td>4327.423268</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5292.078175</td>\n",
       "      <td>6634.370556</td>\n",
       "      <td>4444.335138</td>\n",
       "      <td>4888.286021</td>\n",
       "      <td>3265.391352</td>\n",
       "      <td>4887.560190</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5595.227928</td>\n",
       "      <td>4754.860698</td>\n",
       "      <td>2977.856511</td>\n",
       "      <td>3462.490957</td>\n",
       "      <td>3609.264559</td>\n",
       "      <td>4268.641413</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5126.693267</td>\n",
       "      <td>6009.649079</td>\n",
       "      <td>3811.569943</td>\n",
       "      <td>4744.115976</td>\n",
       "      <td>3829.516831</td>\n",
       "      <td>5097.491872</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Fresh         Milk      Grocery       Frozen  Detergents_Paper  \\\n",
       "0  6623.613537  5513.093240  6019.057354  5669.568008       5898.660607   \n",
       "1  5642.542497  5829.866565  3960.339943  4270.020548       3498.818262   \n",
       "2  5292.078175  6634.370556  4444.335138  4888.286021       3265.391352   \n",
       "3  5595.227928  4754.860698  2977.856511  3462.490957       3609.264559   \n",
       "4  5126.693267  6009.649079  3811.569943  4744.115976       3829.516831   \n",
       "\n",
       "    Delicassen  Channel  \n",
       "0  5179.234947        2  \n",
       "1  4327.423268        2  \n",
       "2  4887.560190        2  \n",
       "3  4268.641413        0  \n",
       "4  5097.491872        2  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd; pd.set_option('display.max_column', 100)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import pandas_profiling as pp\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.metrics import roc_curve, classification_report, confusion_matrix\n",
    "\n",
    "## define bucket in which you are trying to reach\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'daltondencklau-data445-bucket'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "## define csv file to read in the bucket\n",
    "file_key= 'MarketingData.csv'\n",
    "\n",
    "## syntax to allow us to read the file\n",
    "bucket_object = bucket.Object(file_key)\n",
    "file_object = bucket_object.get()\n",
    "file_content_stream = file_object.get('Body')\n",
    "\n",
    "## reading the training data file\n",
    "marketing_data = pd.read_csv(file_content_stream)\n",
    "marketing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c6366db-d498-4384-94c1-b2b693e907bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## reporting the number of observations in each marketing channel\n",
    "marketing_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddb8d37-7142-44b5-b820-74b72cdcd284",
   "metadata": {},
   "source": [
    "### Model Building: Random Forest\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e16a7729-9160-4b98-abb0-a9e05d3f4927",
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining inputs and targets\n",
    "x = marketing_data.drop(columns = 'Channel')\n",
    "y = marketing_data['Channel']\n",
    "\n",
    "## splitting the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa49f829-59b4-4e03-8d0d-8ceffbfbf583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One vs One:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.72      0.74      1001\n",
      "           1       0.65      0.76      0.70      1000\n",
      "           2       0.85      0.63      0.72       998\n",
      "           3       0.78      0.90      0.83      1001\n",
      "\n",
      "    accuracy                           0.75      4000\n",
      "   macro avg       0.76      0.75      0.75      4000\n",
      "weighted avg       0.76      0.75      0.75      4000\n",
      "\n",
      "One vs All:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.72      0.73      1001\n",
      "           1       0.77      0.63      0.69      1000\n",
      "           2       0.72      0.81      0.76       998\n",
      "           3       0.80      0.87      0.83      1001\n",
      "\n",
      "    accuracy                           0.76      4000\n",
      "   macro avg       0.76      0.76      0.75      4000\n",
      "weighted avg       0.76      0.76      0.75      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### One vs One Classifier, One vs Rest Classifier\n",
    "one_vs_one_rf = OneVsOneClassifier(estimator = RandomForestClassifier(n_estimators = 500, max_depth = 3)).fit(x_train, y_train)\n",
    "one_vs_all_rf = OneVsRestClassifier(estimator = RandomForestClassifier(n_estimators = 500, max_depth = 3)).fit(x_train, y_train)\n",
    "\n",
    "## predicting on the testing dataset\n",
    "one_vs_one_rf_preds = one_vs_one_rf.predict(x_test)\n",
    "one_vs_all_rf_preds = one_vs_all_rf.predict_proba(x_test)\n",
    "\n",
    "## changing likelihoods to labels\n",
    "## one_vs_one_rf_preds = np.argmax(one_vs_one_rf_preds, axis = 1) # don't need this statement with .predict statements\n",
    "one_vs_all_rf_preds = np.argmax(one_vs_all_rf_preds, axis = 1) # got rid of the + 1 statement\n",
    "\n",
    "## printing classification report ONE V ONE\n",
    "print('One vs One:')\n",
    "print(classification_report(y_test, one_vs_one_rf_preds))\n",
    "\n",
    "## printing classification report ONE V REST\n",
    "print('One vs All:')\n",
    "print(classification_report(y_test, one_vs_all_rf_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882c7396-fff3-432e-826c-6db5f9a85f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "### why does one vs one not require predict_proba?\n",
    "\n",
    "### why does one vs one not require the np.argmax function?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe53734-2576-45ce-a6c4-e260c262be28",
   "metadata": {},
   "source": [
    "### Model Building: CatBoost\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5c258b7c-b223-465a-b235-473451e76b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One vs One:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90      1001\n",
      "           1       0.86      0.84      0.85      1000\n",
      "           2       0.91      0.92      0.92       998\n",
      "           3       0.89      0.88      0.89      1001\n",
      "\n",
      "    accuracy                           0.89      4000\n",
      "   macro avg       0.89      0.89      0.89      4000\n",
      "weighted avg       0.89      0.89      0.89      4000\n",
      "\n",
      "One vs All:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.89      1001\n",
      "           1       0.85      0.83      0.84      1000\n",
      "           2       0.91      0.91      0.91       998\n",
      "           3       0.88      0.89      0.89      1001\n",
      "\n",
      "    accuracy                           0.88      4000\n",
      "   macro avg       0.88      0.88      0.88      4000\n",
      "weighted avg       0.88      0.88      0.88      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### One vs One Classifier, One vs Rest Classifier\n",
    "one_vs_one_rf = OneVsOneClassifier(estimator = CatBoostClassifier(n_estimators = 500, max_depth = 3, verbose = False, learning_rate = 0.1)).fit(x_train, y_train)\n",
    "one_vs_all_rf = OneVsRestClassifier(estimator = CatBoostClassifier(n_estimators = 500, max_depth = 3, verbose = False, learning_rate = 0.1)).fit(x_train, y_train)\n",
    "\n",
    "## predicting on the testing dataset\n",
    "one_vs_one_rf_preds = one_vs_one_rf.predict(x_test)\n",
    "one_vs_all_rf_preds = one_vs_all_rf.predict_proba(x_test)\n",
    "\n",
    "## changing likelihoods to labels\n",
    "## one_vs_one_rf_preds = np.argmax(one_vs_one_rf_preds, axis = 1) # don't need this statement with .predict statements\n",
    "one_vs_all_rf_preds = np.argmax(one_vs_all_rf_preds, axis = 1) # got rid of the + 1 statement\n",
    "\n",
    "## printing classification report ONE V ONE\n",
    "print('One vs One:')\n",
    "print(classification_report(y_test, one_vs_one_rf_preds))\n",
    "\n",
    "## printing classification report ONE V REST\n",
    "print('One vs All:')\n",
    "print(classification_report(y_test, one_vs_all_rf_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0d6727-75fc-43a3-871b-aebcf51cf239",
   "metadata": {},
   "source": [
    "Based on the above models, I would chose to do **One vs One with CatBoostClassifier** (supplemental information found here: https://catboost.ai/en/docs/concepts/python-reference_catboostclassifier) because it received an F1 score of 0.9, compared to the One vs All CatBoostClassifier (0.89 F1 score), One vs One Random Forest (0.74 F1 score), and One vs All Random Forest (0.73 F1 score). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c977da-d5c7-462a-b4ff-5ff8a396ce26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
